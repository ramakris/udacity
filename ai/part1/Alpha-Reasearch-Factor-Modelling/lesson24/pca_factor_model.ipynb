{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA as a Factor Model - Coding Exercises\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "As we learned in the previous lessons, we can use PCA to create a factor model of risk. Our risk factor model represents the return as:\n",
    "\n",
    "$$\n",
    "\\textbf{r} = \\textbf{B}\\textbf{f} + \\textbf{s}\n",
    "$$\n",
    "\n",
    "where $\\textbf{r}$ is a matrix containing the asset returns, $\\textbf{B}$ is a matrix representing the factor exposures, $\\textbf{f}$ is the matrix of factor returns, and $\\textbf{s}$ is the idiosyncratic risk (also known as the company specific risk).\n",
    "\n",
    "In this notebook, we will use real stock data to calculate:\n",
    "\n",
    "* The Factor Exposures (Factor Betas) $\\textbf{B}$\n",
    "* The Factor Returns $\\textbf{f}$\n",
    "* The Idiosyncratic Risk Matrix $\\textbf{S}$\n",
    "* The Factor Covariance Matrix $\\textbf{F}$\n",
    "\n",
    "We will then combine these quantities to create our Risk Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zipline===1.3.0 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/be/59/8c5802a7897c1095fdc409fb557f04df8f75c37174e80d2ba58c8d8a6488/zipline-1.3.0.tar.gz (2.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.5MB 186kB/s eta 0:00:01   34% |███████████                     | 839kB 8.8MB/s eta 0:00:01    52% |█████████████████               | 1.3MB 10.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pip>=7.1.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: setuptools>18.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Collecting Logbook>=0.12.5 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/fc/3e7557ed1ef1bd4e3ee189fc670416abfc7192b550e8d3c1d858a63f41ab/Logbook-1.4.1.tar.gz (84kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 4.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2016.4 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Collecting requests-file>=1.4.1 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: pandas<=0.22,>=0.18.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Collecting pandas-datareader>=0.2.1 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/5c/ea5b6dcfd0f55c5fb1e37fb45335ec01cceca199b8a79339137f5ed269e0/pandas_datareader-0.7.0-py2.py3-none-any.whl (111kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 3.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: python-dateutil>=2.4.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: requests>=2.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: Cython>=0.25.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Collecting cyordereddict>=0.2.2 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/1a/364cbfd927be1b743c7f0a985a7f1f7e8a51469619f9fefe4ee9240ba210/cyordereddict-1.0.0.tar.gz (138kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 2.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting bottleneck>=1.0.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/05/ae/cedf5323f398ab4e4ff92d6c431a3e1c6a186f9b41ab3e8258dff786a290/Bottleneck-1.2.1.tar.gz (105kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 3.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting contextlib2>=0.4.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: decorator>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: networkx<2.0,>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: numexpr>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Collecting bcolz<1,>=0.12.1 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/8b/1ffa01f872cac36173c5eb95b58c01040d8d25f1b242c48577f4104cd3ab/bcolz-0.12.1.tar.gz (622kB)\n",
      "\u001b[K    100% |████████████████████████████████| 624kB 707kB/s eta 0:00:01    34% |███████████                     | 215kB 14.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Collecting multipledispatch>=0.4.8 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/89/79/429ecef45fd5e4504f7474d4c3c3c4668c267be3370e4c2fd33e61506833/multipledispatch-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: Mako>=1.0.1 in /opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: sqlalchemy>=1.0.8 in /opt/conda/lib/python3.6/site-packages (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Collecting alembic>=0.7.7 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/f3/e60af9a36ae3b8cafabc7e0834d8df6a2965b3feecf27b9b11352dc05dd4/alembic-1.0.2.tar.gz (1.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 441kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers>=1.4.4 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/be/e3/a065de5fdd5849450a8a16a52a96c8db5f498f245e7eda06cc6725d04b80/sortedcontainers-2.0.5-py2.py3-none-any.whl\n",
      "Collecting intervaltree>=2.1.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/c1/450d109b70fa58ca9d77972b02f69222412f9175ccf99fdeaf167be9583c/intervaltree-2.1.0.tar.gz\n",
      "Collecting lru-dict>=1.1.4 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/00/a5/32ed6e10246cd341ca8cc205acea5d208e4053f48a4dced2b1b31d45ba3f/lru-dict-1.1.6.tar.gz\n",
      "Collecting empyrical>=0.5.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/55/a01b05162b764830dbbac868462f44cd847a5b6523a01ca9f955721819da/empyrical-0.5.0.tar.gz (49kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tables>=3.3.0 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/1b/21f4c7f296b718575c17ef25e61c05742a283c45077b4c8d5a190b3e0b59/tables-3.4.4-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.8MB 122kB/s eta 0:00:01    25% |████████▎                       | 972kB 25.1MB/s eta 0:00:01    62% |███████████████████▉            | 2.3MB 27.4MB/s eta 0:00:01    95% |██████████████████████████████▌ | 3.6MB 32.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting trading-calendars>=1.0.1 (from zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/e9/e9e2aeadacab58580ed9493e6c252f051cd8ee9d7efbe49d2f041371c45d/trading_calendars-1.5.1.tar.gz (93kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 4.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting wrapt (from pandas-datareader>=0.2.1->zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.6/site-packages (from pandas-datareader>=0.2.1->zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.9.1->zipline===1.3.0->-r requirements.txt (line 1))\n",
      "Collecting python-editor>=0.3 (from alembic>=0.7.7->zipline===1.3.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/65/1e/adf6e000ea5dc909aa420352d6ba37f16434c8a3c2fa030445411a1ed545/python-editor-1.0.3.tar.gz\n",
      "Building wheels for collected packages: zipline, Logbook, cyordereddict, bottleneck, bcolz, alembic, intervaltree, lru-dict, empyrical, trading-calendars, wrapt, python-editor\n",
      "  Running setup.py bdist_wheel for zipline ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a4/d6/67/f303ab028b004bf8e00c05b5b04fba83d8ec238b6547becdb7\n",
      "  Running setup.py bdist_wheel for Logbook ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/06/13/e9/88e9e8184d89671ffc754dc80f5eb01dabd72071bdb802c5d1\n",
      "  Running setup.py bdist_wheel for cyordereddict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/0b/9d/8b/5bf3e22c1edd59b50f11bb19dec9dfcfe5a479fc7ace02b61f\n",
      "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f2/bf/ec/e0f39aa27001525ad455139ee57ec7d0776fe074dfd78c97e4\n",
      "  Running setup.py bdist_wheel for bcolz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c5/cc/1b/2cf1f88959af5d7f4d449b7fc6c9452d0ecbd86fd61a9ee376\n",
      "  Running setup.py bdist_wheel for alembic ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/95/f3/c2/22155963496514f044049f5c96e2757b9838da4a5cae34e76e\n",
      "  Running setup.py bdist_wheel for intervaltree ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/6b/cf/b0/f7ef2d0f504d26f3e9e70c2369e5725591ccfaf67d528fcbc5\n",
      "  Running setup.py bdist_wheel for lru-dict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/b7/ef/06/fbdd555907a7d438fb33e4c8675f771ff1cf41917284c51ebf\n",
      "  Running setup.py bdist_wheel for empyrical ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/83/14/73/34fb27552601518d28bd0813d75124be76d94ab29152c69112\n",
      "  Running setup.py bdist_wheel for trading-calendars ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/13/0f/d5/517a7a51d9998c20483d777bf2e35e71ec17445509a9ac4cc1\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
      "  Running setup.py bdist_wheel for python-editor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/36/e0/98/ba386b125a00ea9dd52e2c16aa2ec0adbbd639b84bfe2e001d\n",
      "Successfully built zipline Logbook cyordereddict bottleneck bcolz alembic intervaltree lru-dict empyrical trading-calendars wrapt python-editor\n",
      "Installing collected packages: Logbook, requests-file, wrapt, pandas-datareader, cyordereddict, bottleneck, contextlib2, bcolz, multipledispatch, python-editor, alembic, sortedcontainers, intervaltree, lru-dict, empyrical, tables, trading-calendars, zipline\n",
      "Successfully installed Logbook-1.4.1 alembic-1.0.2 bcolz-0.12.1 bottleneck-1.2.1 contextlib2-0.5.5 cyordereddict-1.0.0 empyrical-0.5.0 intervaltree-2.1.0 lru-dict-1.1.6 multipledispatch-0.6.0 pandas-datareader-0.7.0 python-editor-1.0.3 requests-file-1.4.3 sortedcontainers-2.0.5 tables-3.4.4 trading-calendars-1.5.1 wrapt-1.10.11 zipline-1.3.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Returns\n",
    "\n",
    "In this notebook, we will get the stock returns using Zipline and data from Quotemedia, just as we learned in previous lessons. The function `get_returns(start_date, end_date)` in the `utils` module, gets the data from the Quotemedia data bundle and produces the stock returns for the given `start_date` and `end_date`. You are welcome to take a look at the `utils` module to see how this is done.\n",
    "\n",
    "In the code below, we use `utils.get_returns` funtion to get the returns for stock data between `2011-01-05` and `2016-01-05`. You can change the start and end dates, but if you do, you have to make sure the dates are valid trading dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "# Get the returns for the fiven start and end date. Both dates must be valid trading dates\n",
    "returns = utils.get_returns(start_date='2011-01-05', end_date='2016-01-05')\n",
    "\n",
    "# Display the first rows of the returns\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Factor Exposures\n",
    "\n",
    "In the code below, write a function, `factor_betas(pca, factor_beta_indices, factor_beta_columns)` that calculates the factor exposures from Scikit-Learn's `PCA()` class. Remember the matrix of factor exposures, $\\textbf{B}$, describes the coordintates of the Principal Components in the original basis. The `pca` parameter must be a Scikit-Learn's pca object, that has fit the model with the returns. In other words, you must first run `pca.fit(returns)` before passing this parameter into the function. Later in this notebook we will create a function, `fit_pca()`, that will fit the pca model and return the `pca`object. The `factor_beta_indices` parameter must be a 1 dimensional ndarray containg the column names of the `returns` dataframe. The `factor_beta_columns` parameter must be a 1 dimensional ndarray containing evenly spaced integers from 0 up to the number of principal components you used in your `pca` model minus one. For example, if you used 5 principal compoenents in your `pca` model, `pca = PCA(n_components = 5)`, then `factor_beta_columns = [0, 1, 2, 3, 4]`. This function has to return a Pandas dataframe with the factor exposures, where the `factor_beta_indices` correspond to the indices of the dataframe and the `factor_beta_columns` correspond to the column names of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_betas(pca, factor_beta_indices, factor_beta_columns):\n",
    "\n",
    "    #Implement Function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Factor Retuns\n",
    "\n",
    "In the code below, write a function, `factor_returns(pca, returns, factor_return_indices, factor_return_columns)` that calculates the factor returns from Scikit-Learn's `PCA()` class. Remember the matrix of factor returns, $\\textbf{f}$, represents the `returns` written in the **new** basis. The `pca` parameter must be a Scikit-Learn's pca object, that has fit the model with the returns. In other words, you must first run `pca.fit(returns)` before passing this parameter into the function. Later in this notebook we will create a function, `fit_pca()`, that will fit the pca model and return the `pca`object. The `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `factor_return_indices` parameter must be a 1 dimensional ndarray containing the trading dates (Pandas `DatetimeIndex`) in the `returns` dataframe. The `factor_return_columns` parameter must be a 1 dimensional ndarray containing evenly spaced integers from 0 up to the number of principal components you used in your `pca` model minus one. For example, if you used 5 principal compoenents in your `pca` model, `pca = PCA(n_components = 5)`, then `factor_beta_columns = [0, 1, 2, 3, 4]`. This function has to return a Pandas dataframe with the factor returns, where the `factor_return_indices` correspond to the indices of the dataframe and the `factor_return_columns` correspond to the column names of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "def factor_returns(pca, returns, factor_return_indices, factor_return_columns):\n",
    "    \n",
    "    #Implement Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Idiosyncratic Risk Matrix\n",
    "\n",
    "Let's review how we can calculate the Idiosyncratic Risk Matrix $\\textbf{S}$. We know that: \n",
    "\n",
    "$$\n",
    "\\textbf{s} = \\textbf{r} - \\textbf{B}\\textbf{f}\n",
    "$$\n",
    "\n",
    "We refer to $\\textbf{s}$ as the residuals. To calculate the idiosyncratic or specific risk matrix $\\textbf{S}$, we have to calculate the covariance matrix of the residuals, $\\textbf{s}$, and set the off-diagonal elements to zero. \n",
    "\n",
    "With this in mind, in the code below cerate a function, `idiosyncratic_var_matrix(returns, factor_returns, factor_betas, ann_factor)` that calclates the **annualized** Idiosyncratic Risk Matrix. The `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `factor_returns` parameter is the output of the `factor_returns()` function created above. Similarly, the `factor_betas` parameter is the output of the `factor_betas()` function created above. The `ann_factor` parameter is an integer representing the annualization factor. \n",
    "\n",
    "Remember that if the `returns` time series are daily returns, then when we calculate the Idiosyncratic Risk Matrix we will get values on a daily basis. We can annualize these values simply by multiplying the whole Idiosyncratic Risk Matrix by an annualization factor of 252. Remember we don't need the square root of the factor because our numbers here are variances not standard deviations.\n",
    "\n",
    "The function must return a pandas dataframe with the annualized Idiosyncratic Risk Matrix containing the covariance of the residuals in its main diagonal and with all the off-diagonal elements set to zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idiosyncratic_var_matrix(returns, factor_returns, factor_betas, ann_factor):\n",
    "    \n",
    "    #Implement Function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Factor Covariance Matrix\n",
    "\n",
    "To calculate the annualized factor covariance matrix, $\\textbf{F}$, we use the following equation:\n",
    "\n",
    "$$\n",
    "\\textbf{F} = \\frac{1}{N -1}\\textbf{f}\\textbf{f}^T\n",
    "$$\n",
    "\n",
    "where, $N$ is the number of elements in $\\textbf{f}$. Recall that the factor covariance matrix, $\\textbf{F}$, is a diagonal matrix.\n",
    "\n",
    "With this in mind, create a function, `factor_cov_matrix(factor_returns, ann_factor)` that calculates the annualized factor covariance matrix from the factor returns $\\textbf{f}$. The `factor_returns` parameter is the output of the `factor_returns()` function created above and the `ann_factor` parameter is an integer representing the annualization factor. The function must return a diagonal numpy ndarray \n",
    "\n",
    "**HINT :** You can calculate the factor covariance matrix $\\textbf{F}$ very easily using Numpy's `.var` method. The $\\frac{1}{N -1}$ factor can be taken into account using the `ddof` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factor_cov_matrix(factor_returns, ann_factor):\n",
    " \n",
    "    #Implement Function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Perfom PCA\n",
    "\n",
    "In the code below, create a function, `fit_pca(returns, num_factor_exposures, svd_solver)` that uses Scikit-Learn's `PCA()` class to fit the `returns` dataframe with the given number of `num_factor_exposures` (Principal Components) and with the given `svd_solver`. The `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `num_factor_exposures` parameter is an integer representing the number of Principal Components you want to use in your PCA algorithm. The `svd_solver` parameter is a string that determines the type of solver you want to use in your PCA algorithm. To see the type of solvers that you can use, see the [Scikit-Learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). The function must fit the `returns` and return the `pca` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def fit_pca(returns, num_factor_exposures, svd_solver):\n",
    "\n",
    "    #TODO: Implement function\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Create The Risk Model\n",
    "\n",
    "\n",
    "In the code below, create a class:\n",
    "\n",
    "```python\n",
    "class RiskModel(object):\n",
    "    def __init__(self, returns, ann_factor, num_factor_exposures, pca):\n",
    "```\n",
    "\n",
    "where the `returns` parameter is the pandas dataframe of returns given at the begining of the notebook. The `ann_factor` parameter is an integer representing the annualization factor. The `num_factor_exposures` parameter is an integer representing the number of Principal Components you want to use in your PCA algorithm. The `pca` parameter is the output of the `fit_pca()` function created above. The class must contain all the fucntions created above. For example, to include the Factor covariance matrix we will use:\n",
    "\n",
    "```python\n",
    "self.factor_cov_matrix_ = factor_cov_matrix(self.factor_returns_, ann_factor)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RiskModel(object):\n",
    "    \n",
    "    #Implement class\n",
    "  \n",
    "\n",
    "# Set the annualized factor\n",
    "ann_factor = \n",
    "\n",
    "# Set the number of factor exposures (principal components) for the PCA algorithm\n",
    "num_factor_exposures = \n",
    "\n",
    "# Set the svd solver for the PCA algorithm\n",
    "svd_solver = 'full'\n",
    "\n",
    "# Fit the PCA Model using the fit_pca() fucntion \n",
    "pca = \n",
    "\n",
    "# Create a RiskModel object\n",
    "rm = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Factor Exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Factor Exposures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Factor Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Factor Returns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Idiosyncratic Risk Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Idiosyncratic Risk Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Print The Factor Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Factor Covariance Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View The Percent of Variance Explained by Each Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [10.0, 6.0]\n",
    "\n",
    "# Make the bar plot\n",
    "plt.bar(np.arange(num_factor_exposures), pca.explained_variance_ratio_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the first factor dominates. The precise defintion of each factor in a latent model is unknown, however we can guess at the likely intepretation.\n",
    "\n",
    "# View The Factor Returns\n",
    "\n",
    "Remember that the factors returns don't necessarily have direct interpretations in the real world but you can thinik of them as returns time series for some kind of latent or unknown driver of return variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the default figure size\n",
    "plt.rcParams['figure.figsize'] = [10.0, 6.0]\n",
    "\n",
    "rm.factor_returns_.loc[:,0:5].cumsum().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "[Solution notebook](pca_factor_model_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
