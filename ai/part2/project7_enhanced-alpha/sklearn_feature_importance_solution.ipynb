{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance method in sci-kit learn (Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get a sense of how feature importance is calculated in sci-kit learn, and also see where it gives results that we wouldn't expect.\n",
    "\n",
    "Sci-kit learn uses gini impurity to calculate a measure of impurity for each node.  Gini impurity, like entropy is a way to measure how \"disorganized\" the observations are before and after splitting them using a feature. So there is an impurity measure for each node.\n",
    "\n",
    "In the formula, freq_{i} is the frequency of label \"i\".  C is the number of unique labels at that node.\n",
    "\n",
    "$Impurity= \\sum_{i=1}^{C} - freq_{i} * (1- freq_{i})$\n",
    "\n",
    "The node importance in sci-kit learn is calculated as the difference between the gini impurity of the node and the gini impurity of its left and right children.  These gini impurities are weighted by the number of data points that reach each node.\n",
    "\n",
    "$NodeImportance = w_{i} Impurity_{i} - ( w_{left} Impurity_{left} + w_{right} Impurity_{right} )$\n",
    "\n",
    "The importance of a feature is the importance of the node that it was split on, divided by the sum of all node importances in the tree.  You’ll get to practice this in the coding exercise coming up next!\n",
    "\n",
    "For additional reading, please check out this blog post [The Mathematics of Decision Trees, Random Forest and Feature Importance in Scikit-learn and Spark](https://medium.com/@srnghn/the-mathematics-of-decision-trees-random-forest-and-feature-importance-in-scikit-learn-and-spark-f2861df67e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.14.5 in /home/ramak/anaconda3/envs/python_zipline/lib/python3.6/site-packages (1.14.5)\n",
      "Requirement already satisfied: scikit-learn==0.19.1 in /home/ramak/anaconda3/envs/python_zipline/lib/python3.6/site-packages (0.19.1)\n",
      "Requirement already satisfied: graphviz==0.9 in /home/ramak/anaconda3/envs/python_zipline/lib/python3.6/site-packages (0.9)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install numpy==1.14.5\n",
    "!{sys.executable} -m pip install scikit-learn==0.19.1\n",
    "!{sys.executable} -m pip install graphviz==0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data\n",
    "\n",
    "We'll generate features and labels that form the \"AND\" operator.  So when feature 0 and feature 1 are both 1, then the label is 1, else the label is 0.  The third feature, feature 2, won't have an effect on the label output (it's always zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Features 0 and 1 form the AND operator\n",
    "Feature 2 is always zero.\n",
    "\"\"\"\n",
    "N = 100\n",
    "M = 3\n",
    "X = np.zeros((N,M))\n",
    "X.shape\n",
    "y = np.zeros(N)\n",
    "X[:1 * N//4, 1] = 1\n",
    "X[:N//2, 0] = 1\n",
    "X[N//2:3 * N//4, 1] = 1\n",
    "y[:1 * N//4] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe the features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe the labels\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the trained decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"294pt\" height=\"261pt\"\n",
       " viewBox=\"0.00 0.00 294.00 261.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 257)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-257 290,-257 290,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#e58139\" fill-opacity=\"0.666667\" stroke=\"#000000\" d=\"M156,-253C156,-253 70,-253 70,-253 64,-253 58,-247 58,-241 58,-241 58,-201 58,-201 58,-195 64,-189 70,-189 70,-189 156,-189 156,-189 162,-189 168,-195 168,-201 168,-201 168,-241 168,-241 168,-247 162,-253 156,-253\"/>\n",
       "<text text-anchor=\"start\" x=\"87\" y=\"-238.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X</text>\n",
       "<text text-anchor=\"start\" x=\"97\" y=\"-238.8\" font-family=\"Helvetica,sans-Serif\" baseline-shift=\"sub\" font-size=\"14.00\" fill=\"#000000\">1</text>\n",
       "<text text-anchor=\"start\" x=\"104\" y=\"-238.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\"> ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"77.5\" y=\"-224.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.375</text>\n",
       "<text text-anchor=\"start\" x=\"68\" y=\"-210.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100</text>\n",
       "<text text-anchor=\"start\" x=\"66\" y=\"-196.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [75, 25]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M90,-147.5C90,-147.5 12,-147.5 12,-147.5 6,-147.5 0,-141.5 0,-135.5 0,-135.5 0,-106.5 0,-106.5 0,-100.5 6,-94.5 12,-94.5 12,-94.5 90,-94.5 90,-94.5 96,-94.5 102,-100.5 102,-106.5 102,-106.5 102,-135.5 102,-135.5 102,-141.5 96,-147.5 90,-147.5\"/>\n",
       "<text text-anchor=\"start\" x=\"23\" y=\"-132.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"10\" y=\"-117.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-102.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 0]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M93.0415,-188.8089C86.6254,-178.4603 79.4833,-166.9408 72.9333,-156.3764\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.8437,-154.4283 67.5996,-147.7735 69.8944,-158.1169 75.8437,-154.4283\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.8903\" y=\"-168.4129\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"transparent\" stroke=\"#000000\" d=\"M218,-153C218,-153 132,-153 132,-153 126,-153 120,-147 120,-141 120,-141 120,-101 120,-101 120,-95 126,-89 132,-89 132,-89 218,-89 218,-89 224,-89 230,-95 230,-101 230,-101 230,-141 230,-141 230,-147 224,-153 218,-153\"/>\n",
       "<text text-anchor=\"start\" x=\"149\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X</text>\n",
       "<text text-anchor=\"start\" x=\"159\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" baseline-shift=\"sub\" font-size=\"14.00\" fill=\"#000000\">0</text>\n",
       "<text text-anchor=\"start\" x=\"166\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\"> ≤ 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"147\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"134\" y=\"-110.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50</text>\n",
       "<text text-anchor=\"start\" x=\"128\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [25, 25]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M132.9585,-188.8089C138.3237,-180.1553 144.1965,-170.683 149.8063,-161.635\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.7841,-163.4741 155.0789,-153.1308 146.8348,-159.7855 152.7841,-163.4741\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.7882\" y=\"-173.7701\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M154,-53C154,-53 76,-53 76,-53 70,-53 64,-47 64,-41 64,-41 64,-12 64,-12 64,-6 70,0 76,0 76,0 154,0 154,0 160,0 166,-6 166,-12 166,-12 166,-41 166,-41 166,-47 160,-53 154,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"87\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"74\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 25</text>\n",
       "<text text-anchor=\"start\" x=\"72\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [25, 0]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M154.5192,-88.7428C149.0196,-80.0809 143.0438,-70.669 137.4438,-61.849\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"140.3154,-59.842 132.0005,-53.2759 134.4059,-63.5941 140.3154,-59.842\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#399de5\" stroke=\"#000000\" d=\"M274,-53C274,-53 196,-53 196,-53 190,-53 184,-47 184,-41 184,-41 184,-12 184,-12 184,-6 190,0 196,0 196,0 274,0 274,0 280,0 286,-6 286,-12 286,-12 286,-41 286,-41 286,-47 280,-53 274,-53\"/>\n",
       "<text text-anchor=\"start\" x=\"207\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"194\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 25</text>\n",
       "<text text-anchor=\"start\" x=\"192\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 25]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M195.4808,-88.7428C200.9804,-80.0809 206.9562,-70.669 212.5562,-61.849\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"215.5941,-63.5941 217.9995,-53.2759 209.6846,-59.842 215.5941,-63.5941\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f338d4cdf28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = sklearn.tree.export_graphviz(model, out_file=None, filled=True, rounded=True, special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the tree\n",
    "\n",
    "The [source code for Tree](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/tree/_tree.pyx) has useful comments about attributes in the Tree class.  Search for the code that says `cdef class Tree:` for useful comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Tree object\n",
    "tree0 = model.tree_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree attributes are stored in lists\n",
    "\n",
    "The tree data are stored in lists.  Each node is also assigned an integer 0,1,2...  \n",
    "Each node's value for some attribute is stored at the index location that equals the node's assigned integer.\n",
    "\n",
    "For example, node 0 is the root node at the top of the tree.  There is a list called children_left.  Index location 0 contains the left child of node 0.\n",
    "\n",
    "\n",
    "#### left and right child nodes\n",
    "```\n",
    "children_left : array of int, shape [node_count]\n",
    "        children_left[i] holds the node id of the left child of node i.\n",
    "        For leaves, children_left[i] == TREE_LEAF. Otherwise,\n",
    "        children_left[i] > i. This child handles the case where\n",
    "        X[:, feature[i]] <= threshold[i].\n",
    "children_right : array of int, shape [node_count]\n",
    "        children_right[i] holds the node id of the right child of node i.\n",
    "        For leaves, children_right[i] == TREE_LEAF. Otherwise,\n",
    "        children_right[i] > i. This child handles the case where\n",
    "        X[:, feature[i]] > threshold[i].\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree0.children_left: [ 1 -1  3 -1 -1]\n",
      "tree0.children_right: [ 2 -1  4 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"tree0.children_left: {tree0.children_left}\")\n",
    "print(f\"tree0.children_right: {tree0.children_right}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this tree, the index positions 0,1,2,3,4 are the numbers for identifying each node in the tree.  Node 0 is the root node.  Node 1 and 2 are the left and right child of the root node.  So in the list children_left, at index 0, we see 1, and for children_right list, at index 0, we see 2.  \n",
    "\n",
    "-1 is used to denote that there is no child for that node.  Node 1 has no left or right child, so in the children_left list, at index 1, we see -1.  Similarly, in children_right, at index 1, the value is also -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### features used for splitting at each node\n",
    "```\n",
    "    feature : array of int, shape [node_count]\n",
    "        feature[i] holds the feature to split on, for the internal node i.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree0.feature: [ 1 -2  0 -2 -2]\n"
     ]
    }
   ],
   "source": [
    "print(f\"tree0.feature: {tree0.feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature 1 is used to split on node 0.  Feature 0 is used to split on node 2.  The -2 values indicate that these are leaf nodes (no features are used for splitting at those nodes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of samples in each node\n",
    "\n",
    "```\n",
    "n_node_samples : array of int, shape [node_count]\n",
    "        n_node_samples[i] holds the number of training samples reaching node i.\n",
    "\n",
    "weighted_n_node_samples : array of int, shape [node_count]\n",
    "        weighted_n_node_samples[i] holds the weighted number of training samples\n",
    "        reaching node i.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree0.n_node_samples : [100  50  50  25  25]\n",
      "tree0.weighted_n_node_samples : [100.  50.  50.  25.  25.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"tree0.n_node_samples : {tree0.n_node_samples}\")\n",
    "print(f\"tree0.weighted_n_node_samples : {tree0.weighted_n_node_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted_n_node_samples is the same as n_node_samples for decision trees.  It's different for random forests where a sub-sample of data points is used in each tree.  We'll use weighted_n_node_samples in the code below, but either one works when we're calculating the proportion of samples in a left or right child node relative to their parent node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini impurity\n",
    "\n",
    "Gini impurity, like entropy is a way to measure how \"disorganized\" the observations are before and after splitting them using a feature. So there is an impurity value calculated for each node.\n",
    "\n",
    "In the formula, $freq_{i}$ is the frequency of label \"i\".  C is the number of unique labels at that node (C stands for \"Class\", as in \"classifier\".\n",
    "\n",
    "$ \\sum_{i}^{C} - freq_{i} * (1- freq_{i})$\n",
    "\n",
    "```\n",
    "impurity : array of double, shape [node_count]\n",
    "        impurity[i] holds the impurity (i.e., the value of the splitting\n",
    "        criterion) at node i.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the impurity if there is a single class (unique label type)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq0 = 1\n",
    "impurity = -1 * freq0 * (1 - freq0)\n",
    "print(f\"impurity of a homogenous sample with a single label, is: {impurity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the impurity if there are two classes (two distinct labels), and there are 90% of samples for one label, and 10% for the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq1 = 0.9\n",
    "freq2 = 0.1\n",
    "impurity = -1 * freq1 * (1 -freq1) + -1 * freq2 * (1 - freq2)\n",
    "print(f\"impurity when 90% are of one label, and 10% are of the other: {impurity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "What is the impurity if there are two classes of label, and there are 50% of samples for one label, and 50% for the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "What is the impurity if there are two classes of label,\n",
    "and there are 50% of samples for one label, and 50% for the other?\n",
    "\"\"\"\n",
    "# TODO\n",
    "freq1 = 0.5\n",
    "freq2 = 0.5\n",
    "# TODO\n",
    "impurity = -1 * freq1 * (1 - freq1) + -1 * freq2 * (1 - freq2)\n",
    "print(f\"impurity when 50% are of one label, and 50% are of the other: {impurity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "Is the impurity larger or smaller (in magnitude) when the samples are dominated by a single class?  \n",
    "Is the impurity larger or smaller (in magnitude) when the frequency of each class is more evenly distributed among classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "The gini impurity is smaller in magnitude (closer to zero) when the samples are dominated by a single class.  \n",
    "The impurity is larger in magnitude (farther from zero) when there is a more even split among labels in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Importance\n",
    "\n",
    "The node importance in sklearn is calculated as the difference between the gini impurity of the node and the impurities of its child nodes.  These gini impurities are weighted by the number of data points that reach each node.\n",
    "\n",
    "$NodeImportance = w_{i} Impurity_{i} - ( w_{left} Impurity_{left} + w_{right} Impurity_{right} )$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of the node labels\n",
    "Node 0 is the root node, and its left and right children are 1 and 2.  \n",
    "Node 1 is a leaf node  \n",
    "Node 2 has two children, 3 and 4.  \n",
    "Node 3 is a leaf node  \n",
    "Node 4 is a leaf node  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of child nodes\n",
    "print(f\"tree0.children_left: {tree0.children_left}\")\n",
    "print(f\"tree0.children_right: {tree0.children_right}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the node importance of the root node, node 0.  Its child nodes are 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni0 = tree0.weighted_n_node_samples[0] * tree0.impurity[0] - \\\n",
    "        ( tree0.weighted_n_node_samples[1] * tree0.impurity[1] + \\\n",
    "          tree0.weighted_n_node_samples[2] * tree0.impurity[2] )\n",
    "print(f\"Importance of node 0 is {ni0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "Calculate the node importance of node 2.  Its left and right child nodes are 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "ni2 = tree0.weighted_n_node_samples[2] * tree0.impurity[2] - \\\n",
    "        ( tree0.weighted_n_node_samples[3] * tree0.impurity[3] + \\\n",
    "          tree0.weighted_n_node_samples[4] * tree0.impurity[4] )\n",
    "print(f\"Importance of node 2 is {ni2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other nodes are leaf nodes, so there is no decrease in impurity that we can calculate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum the node importances\n",
    "Only nodes 0 and node 2 have node importances.  The others are leaf nodes, so we don't calculate node importances (there is no feature that is used for splitting at those leaf nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "ni_total = ni0 + ni2\n",
    "print(f\"The sum of node importances is {ni_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of which feature is used to split at each node\n",
    "\n",
    "feature 0 was used to split on node 2  \n",
    "feature 1 was used to split on node 0  \n",
    "feature 2 was not used for splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tree0.feature: {tree0.feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz: Calculate importance of the features\n",
    "\n",
    "The importance of a feature is the importance of the node that it was used for splitting, divided by the total node importances.  Calculate the importance of feature 0, 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "fi0 = ni2/ni_total\n",
    "fi1 = ni0/ni_total\n",
    "fi2 = 0/ni_total\n",
    "print(f\"importance of feature 0: {fi0}\")\n",
    "print(f\"importance of feature 1: {fi1}\")\n",
    "print(f\"importance of feature 2: {fi2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check with sklearn\n",
    "\n",
    "Check out how to use [feature importance](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get feature importances from sci-kit learn\n",
    "\n",
    "fi0_skl = model.feature_importances_[0]\n",
    "fi1_skl = model.feature_importances_[1]\n",
    "fi2_skl = model.feature_importances_[2]\n",
    "\n",
    "print(f\"sklearn importance of feature 0: {fi0_skl}\")\n",
    "print(f\"sklearn importance of feature 1: {fi1_skl}\")\n",
    "print(f\"sklearn importance of feature 2: {fi2_skl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notice anything odd?\n",
    "\n",
    "Notice that the data we generated simulates an AND operator.  If feature 0 and feature 1 are both 1, then the output is 1, otherwise 0.  So, from that perspective, do you think that features 0 and 1 are equally important?\n",
    "\n",
    "What do you notice about the feature importance calculated in sklearn?  Are the features considered equally important according to this calculation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer\n",
    "Intuitively, if features 0 and 1 form the AND operator, then it makes sense that they should be equally important in determining the output.  The feature importance calculated in sklearn assigns a higher importance to feature 0 compared to feature 1.  This is because the tree first splits on feature 1, and then when it splits on feature 0, the labels become cleanly split into respective leaf nodes.  \n",
    "\n",
    "In other words, what we observe is that features which are used to split further down the bottom of the tree are given higher importance, using the gini impurity as a measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "If someone tells you that you don't need to understand the algorithm, just how to install the package and call the function, do you agree or disagree with that statement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution notebook\n",
    "[Solution notebook](sklearn_feature_importance_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
